---
title: "Playing With Python's new JIT"
date: 2024-01-05T18:21:46-06:00
draft: true
tags:
- python
- cpython
- jit
description: "Playing with the Upcoming CPython JIT"
---

<p class="post-p">If you haven't read <a href="https://github.com/python/cpython/pull/113465">Brandt Bucher's incredible rhyming Christmas Day PR</a>, drop everything and go do it. Right now.</p>
<p class="post-p">Welcome back! I see that big smile on your face - that poem is really something no? But what does it all mean?</p>
<p class="post-p">Essentially, CPython may be getting a Just-In-Time compiler implementation, at least in distributions where that's possible. There are many flavors of JIT, but their common feature is emitting machine code (or similar) very shortly before <span class="italic">the time that code is actually run.</span> In the case of Brandt's PR, that's done by a method called <span class="font-semibold italic">copy-and-patch</span>, where small snippets of code (one per Python micro-opcode) are pre-compiled to machine code, with 'holes' left for external symbols and constants that can be 'stencilled in' at runtime. Pretty neat!</p>
<p class="post-p">I won't claim to be a JIT expert, or anything close. But I am a tinkerer - so let's pull down Brandt's JIT branch and play around a bit.</p>
<div class="info-banner">For more background on JITs and copy-and-patch specifically, see:
    <ul class="post-ul">
        <li>The <a href="https://dl.acm.org/doi/10.1145/3485513">whitepaper</a>: <span class="italic">Copy-and-patch compilation: a fast compilation algorithm for high-level languages and bytecode</span></li>
        <li>Haoran Xu's <a href="https://sillycross.github.io/2023/05/12/2023-05-12/">blogpost</a>: <span class="italic">Building a baseline JIT for Lua automatically</span></li>
        <li>The <a href="https://www.youtube.com/watch?v=HxSHIpEQRjs">video of Brandt's Presentation</a> at this year's CPython Core Sprint in Brno</li>
        <li>The internals of the <a href="https://github.com/python/cpython/pull/113465">pull request itself</a></li>
    </ul>
</div>

<p class="post-p">Brandt mentions in his talk that performance is roughly comparable to the existing (non-JIT) performance - some overhead cost balanced by improved performance, even before all the 'clever optimisations' happen. It's unclear to me exactly how this is benchmarked - <a href="https://pyperf.readthedocs.io/en/latest/run_benchmark.html#jit-compilers">PyPy in particular is hard to benchmark</a> in a comparable way due to its JIT, and the desire to 'warm up' the code for best JIT performance. (There's a line on <a href="https://github.com/faster-cpython/benchmarking-public">Faster Cpython's Public Benchmarking</a> that implies that the build as of a couple days ago was roughly 5% slower than mainline CPython.)</p>
<p class="post-p">Since I wanted to play with the JIT myself, I set up an environment to run the Faster CPython team's tests locally, based on their <a href="https://github.com/faster-cpython/benchmarking-public/blob/main/.github/workflows/_benchmark.yml"><code>_benchmark</code> GitHub Action</a> and <a href="https://github.com/faster-cpython/bench_runner">bench_runner</a> script. (I did tried to just run the whole action locally using <a href="https://github.com/nektos/act">act</a>, but ran into mysterious issues. You can expand the summary below to see the full list of commands used to run these benchmarks locally.</p>
<details class="ml-4">
    <summary class=""><span class="border-2 border-blue-700 p-1 rounded-md">Shell Commands to run Faster CPython Benchmarks Locally</span></summary>
<div class="m-2 p-2 border-2 border-blue-700">
{{< highlight "sh" "linenostart=1" >}}
git clone https://github.com/faster-cpython/benchmarking-public.git
cd benchmarking-public
git clone https://github.com/{fork-of-cpython}/python.git
cd python
git reset --hard {reference-branch-or-tag}
cd ..
python -m venv venv
venv/bin/python -m pip install -r requirements.txt
git clone https://github.com/pyston/python-macrobenchmarks.git ./pyston-benchmarks
cd pyston-benchmarks
git reset --hard {PYSTON_BENCHMARKS_HASH} # : ee8adbd7846ec67d1a8a362e6a5e876df372431d
cd ..
git clone https://github.com/python/pyperformance.git
cd pyperformance
git reset --hard {PYPERFORMANCE_HASH} # f7f36509e2e81e9a20cfeadddd6608f2378ff26c
cd ..
export PYTHON_UOPS=1
cd cpython
./configure --enable-optimizations --with-lto=yes --enable-experimental-jit
make -j4
cd ..
venv/bin/python -m pip install --no-binary :all: ./pyperformance
venv/bin/python -m pyperf system tune
sudo bash -c "echo 100000 > /proc/sys/kernel/perf_event_max_sample_rate"
rm -rf ~/.debug/*
venv/bin/python -m bench_runner run_benchmarks benchmark cpython/python forkname ref all --run_id $ 1 --flag PYTHON_UOPS --flag JIT
{{< /highlight >}}
</div>
</details>

<p class="post-p">Comparing a basement benchmark (cpython <code>main@802d4954)</code> with the JIT branch (brandtbucher/justin@33427753d0) we see that their speed is roughly comparable </p>
<p class="post-p">You can toggle open the full output from <code>pyperf</code> if you're interested</p>
<details class="ml-4">
    <summary><span class="border-2 border-blue-700 p-1 rounded-md">Full Benchmarking Comparison</span></summary>
    <div class="m-4 p-2 border-2 border-blue-700">
        <h1 id="benchmarks-with-tag-apps-">Benchmarks with tag &#39;apps&#39;:</h1>
        <table>
        <thead>
        <tr>
        <th>Benchmark</th>
        <th style="text-align:center">benchmark</th>
        <th style="text-align:center">benchmark_jit</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td>docutils</td>
        <td style="text-align:center">7.65 sec</td>
        <td style="text-align:center">7.13 sec: 1.07x faster</td>
        </tr>
        <tr>
        <td>Geometric mean</td>
        <td style="text-align:center">(ref)</td>
        <td style="text-align:center">1.01x faster</td>
        </tr>
        </tbody>
        </table>
        <p>Benchmark hidden because not significant (4): 2to3, chameleon, html5lib, tornado_http</p>
        <h1 id="benchmarks-with-tag-asyncio-">Benchmarks with tag &#39;asyncio&#39;:</h1>
        <p>Benchmark hidden because not significant (4): async_tree_none, async_tree_cpu_io_mixed, async_tree_io, async_tree_memoization</p>
        <h1 id="benchmarks-with-tag-math-">Benchmarks with tag &#39;math&#39;:</h1>
        <p>Benchmark hidden because not significant (3): float, nbody, pidigits</p>
        <h1 id="benchmarks-with-tag-regex-">Benchmarks with tag &#39;regex&#39;:</h1>
        <p>Benchmark hidden because not significant (4): regex_compile, regex_dna, regex_effbot, regex_v8</p>
        <h1 id="benchmarks-with-tag-serialize-">Benchmarks with tag &#39;serialize&#39;:</h1>
        <table>
        <thead>
        <tr>
        <th>Benchmark</th>
        <th style="text-align:center">benchmark</th>
        <th style="text-align:center">benchmark_jit</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td>tomli_loads</td>
        <td style="text-align:center">6.75 sec</td>
        <td style="text-align:center">6.71 sec: 1.01x faster</td>
        </tr>
        <tr>
        <td>Geometric mean</td>
        <td style="text-align:center">(ref)</td>
        <td style="text-align:center">1.00x faster</td>
        </tr>
        </tbody>
        </table>
        <p>Benchmark hidden because not significant (13): json_dumps, json_loads, pickle, pickle_dict, pickle_list, pickle_pure_python, unpickle, unpickle_list, unpickle_pure_python, xml_etree_parse, xml_etree_iterparse, xml_etree_generate, xml_etree_process</p>
        <h1 id="benchmarks-with-tag-startup-">Benchmarks with tag &#39;startup&#39;:</h1>
        <p>Benchmark hidden because not significant (2): python_startup, python_startup_no_site</p>
        <h1 id="benchmarks-with-tag-template-">Benchmarks with tag &#39;template&#39;:</h1>
        <p>Benchmark hidden because not significant (4): django_template, genshi_text, genshi_xml, mako</p>
        <h1 id="all-benchmarks-">All benchmarks:</h1>
        <table>
        <thead>
        <tr>
        <th>Benchmark</th>
        <th style="text-align:center">benchmark</th>
        <th style="text-align:center">benchmark_jit</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td>aiohttp</td>
        <td style="text-align:center">2.78 ms</td>
        <td style="text-align:center">2.75 ms: 1.01x faster</td>
        </tr>
        <tr>
        <td>asyncio_tcp</td>
        <td style="text-align:center">1.78 sec</td>
        <td style="text-align:center">1.76 sec: 1.01x faster</td>
        </tr>
        <tr>
        <td>crypto_pyaes</td>
        <td style="text-align:center">281 ms</td>
        <td style="text-align:center">272 ms: 1.04x faster</td>
        </tr>
        <tr>
        <td>docutils</td>
        <td style="text-align:center">7.65 sec</td>
        <td style="text-align:center">7.13 sec: 1.07x faster</td>
        </tr>
        <tr>
        <td>fannkuch</td>
        <td style="text-align:center">1.11 sec</td>
        <td style="text-align:center">1.10 sec: 1.01x faster</td>
        </tr>
        <tr>
        <td>flaskblogging</td>
        <td style="text-align:center">8.67 ms</td>
        <td style="text-align:center">8.75 ms: 1.01x slower</td>
        </tr>
        <tr>
        <td>create_gc_cycles</td>
        <td style="text-align:center">3.10 ms</td>
        <td style="text-align:center">3.05 ms: 1.02x faster</td>
        </tr>
        <tr>
        <td>gc_traversal</td>
        <td style="text-align:center">7.43 ms</td>
        <td style="text-align:center">7.33 ms: 1.01x faster</td>
        </tr>
        <tr>
        <td>gunicorn</td>
        <td style="text-align:center">2.78 ms</td>
        <td style="text-align:center">2.74 ms: 1.02x faster</td>
        </tr>
        <tr>
        <td>logging_format</td>
        <td style="text-align:center">23.8 us</td>
        <td style="text-align:center">23.4 us: 1.02x faster</td>
        </tr>
        <tr>
        <td>mdp</td>
        <td style="text-align:center">7.03 sec</td>
        <td style="text-align:center">6.99 sec: 1.01x faster</td>
        </tr>
        <tr>
        <td>mypy2</td>
        <td style="text-align:center">2.03 sec</td>
        <td style="text-align:center">2.02 sec: 1.01x faster</td>
        </tr>
        <tr>
        <td>pycparser</td>
        <td style="text-align:center">3.61 sec</td>
        <td style="text-align:center">3.58 sec: 1.01x faster</td>
        </tr>
        <tr>
        <td>scimark_fft</td>
        <td style="text-align:center">968 ms</td>
        <td style="text-align:center">957 ms: 1.01x faster</td>
        </tr>
        <tr>
        <td>scimark_sparse_mat_mult</td>
        <td style="text-align:center">12.8 ms</td>
        <td style="text-align:center">12.5 ms: 1.02x faster</td>
        </tr>
        <tr>
        <td>sqlite_synth</td>
        <td style="text-align:center">5.29 us</td>
        <td style="text-align:center">5.35 us: 1.01x slower</td>
        </tr>
        <tr>
        <td>sympy_str</td>
        <td style="text-align:center">792 ms</td>
        <td style="text-align:center">784 ms: 1.01x faster</td>
        </tr>
        <tr>
        <td>tomli_loads</td>
        <td style="text-align:center">6.75 sec</td>
        <td style="text-align:center">6.71 sec: 1.01x faster</td>
        </tr>
        <tr>
        <td>Geometric mean</td>
        <td style="text-align:center">(ref)</td>
        <td style="text-align:center">1.00x faster</td>
        </tr>
        </tbody>
        </table>
        <p>Benchmark hidden because not significant (82): 2to3, async_generators, async_tree_none, async_tree_cpu_io_mixed, async_tree_io, async_tree_memoization, asyncio_tcp_ssl, asyncio_websockets, chameleon, chaos, comprehensions, bench_mp_pool, bench_thread_pool, coroutines, coverage, dask, deepcopy, deepcopy_reduce, deepcopy_memo, deltablue, django_template, dulwich_log, float, generators, genshi_text, genshi_xml, go, hexiom, html5lib, json, json_dumps, json_loads, logging_silent, logging_simple, mako, meteor_contest, nbody, nqueens, pathlib, pickle, pickle_dict, pickle_list, pickle_pure_python, pidigits, pprint_safe_repr, pprint_pformat, pyflate, pylint, python_startup, python_startup_no_site, raytrace, regex_compile, regex_dna, regex_effbot, regex_v8, richards, richards_super, scimark_lu, scimark_monte_carlo, scimark_sor, spectral_norm, sqlalchemy_declarative, sqlalchemy_imperative, sqlglot_parse, sqlglot_transpile, sqlglot_optimize, sqlglot_normalize, sympy_expand, sympy_integrate, sympy_sum, telco, thrift, tornado_http, typing_runtime_protocols, unpack_sequence, unpickle, unpickle_list, unpickle_pure_python, xml_etree_parse, xml_etree_iterparse, xml_etree_generate, xml_etree_process</p>
    </div>

</details>

<p class="post-h2"><code>build.py</code></p>
<pre>
<code>
main()
get_target() takes some <a href="https://peps.python.org/pep-0011/">PEP11 triple</a> and returns a Target object (really, subclass of Target class specified by Triple - ELF, C0FF, etc)
target.build():
    Takes CWD
    Creates file out/jit_stencils.h
    creates a hasher, updates it what PythonExecutorCases, pyconfig.h, jit tools folder
        If the stencils_file exists and has same hash - returns

target runs stencil_groups = self.build_stencils()
    Gets executor cases from executor_cases.c.h (file generated by Tools/cases_generato/tier2_generator.py)
    Gets op names using a regex over this file to grab case names
    For op in opnames:
        create a coroutine with self._compile(opname, template.c, a_temp_directory)

        self._compile:
            with a bunch of flags, esp "-D_JIT_OPCODE={opname}", run clang template.c
            output to '{opname}.o'
            return self.parse(this file)
        
            self.parse(path):
                creates new StencilGroup called group

                Finds llvm-objdump
                runs output = objdump --disassemble --reloc on path
                group.code.disassembled gets lines of disassembled output

                also!
                Find llvm-readobj
                output = llvm-readobj --elf-output-style=JSON --expand-relocs --section-data --section-relocations --section-symbols --sections,
                Remove "PrivateExtern, Extern" for Mach-0
                For COFF, only use things inside []

                sections = JSON.loads(output)
                for section in sections:
                    self._handle_section(section, group)
                
                    _handle_section() is implemented in Target subplaces
                    Processes and handles symbol naming, relocations (via _handle_relocations)

                After that's all done, call self._process_relocations to calculate hole values, symbols, and offsets in the code stencil_groups
                Do a little magic for aarch64_trampoline()?
                Collect holes in a list group.code.holes
                process relocations on group.data
                return group
    
    Collect results of coroutine into a dict by opname: compilation result, and return

    Dump this dictionary using dump():
        dump_header():
            Records enums HoleKind, HoleValue, (as calculated)
            Records static enums Hole, Stencil, StencilGroup

        Dump the opname and disassembly as a comment
        Yield body code as array of bytes, with size pre-calculated
        Loop over holes if any, emit line with hole offset, kind, value, symbol if any

        Do the same with data body and holes
        (Only opcode with data_holes is _CONVERT_VALUE)

        dump_footer():
            define INIT_STENCIL macro which takes a stencil and outputs body size, body, holes_size, and holes
            INIT_STENCIL_GROUP(OP) makes .code and .data from the inited stencils_file
            An array (Of size 512) that INIT_STENCIL_GROUP's each opcode

            Emit Get_Patches which makes HoleValue_XXX = 0xBADBADBADBADBADBADBADB
            ????????????????????
            Presumably to error if a hole doesn't get filled??

        






target calls dump(stencil_groups)
</code>
</pre>

<h2 class="post-h2">Your Own Playground</h2>
<p class="post-p">If you want to try out JIT'd Python for yourself, here's a quick and dirty </p>
<ol>
    <li>Clone the jit branch at <code>https://github.com/brandtbucher/cpython.git</code>.</li>
    <li>Run <code>configure --enable-experimental-jit --with-pydebug --ensure-pip=install</code></li>
    <li>Run <code>make</code></li>
    <li>Run <code>./python</code> to drop into a REPL with your freshly built python</li>
    <li><code>make altinstall</code></li>
</ol>

<p class="post-p">To profile one way:</p>

<ol>
    <li><code>./python -m pyperf system_tune</code></li>
    <li><code>./python -m pip install pyperformance</code></li>
    <li><code>./python -m pyperformance run -o base.json</code></li>
</ol>

<p class="post-p">To benchmark a-la faster-cpython:</p>

{{< highlight "sh" "linenostart=1" >}}
to debug, core dump:
ulimit -c unlimited
gdb _bootstrap_python
core /var/lib/apport/coredump/core.XXXXXXXXX
where
bt -full

gdb --args ./_bootstrap_python ./Programs/_freeze_module.py posixpath ./Lib/posixpath.py Python/frozen_modules/posixpath.h
{{< /highlight >}}


----------

Run a single test in new python with stats, dumping pystats data to data.txt
./python -X pystats -m pyperformance run -b (NAME) -o stats.json 2>data.txt

To output summary, make a folder that has only the data file in it
./python ./Tools/scripts/summarize_stats.py /home/jglass/Documents/cpython/rundata > out.md


------------

Notes about OpArgs, Operands, and Targets

Target
    Optimizer.c
        @ 418, in `translate_bytecode_to_trace`, target is set with `target = INSTR_IP(instr, code), where 
            instr is a _Py_CODEUNIT*
                typedef union {
                    uint16_t cache;
                    struct {
                        uint8_t code;
                        uint8_t arg;
                    } op;
                } _Py_CODEUNIT;
            code is a PyCodeObject*
                defined in code.h
                Constructor Macro takes a SIZE (code is SIZE 1)
                has an array co_code_adaptive[(SIZE)]
            INSTR_UP is
                #define INSTR_IP(INSTR, CODE) \
                (
                    (uint32_t)(
                            INSTR - ((_Py_CODEUNIT *)(CODE)->co_code_adaptive)
                        )
                )

Constructing a Trace
    `translate_bytecode_to_trace`:
        Starts with a
        @ 594 - ADD_TO_TRACE(uop, oparg, operand, target)


<p> Main with JIT (31.8MB) vs JIT279 (31.7MB): 6% faster with some wild outliers

Benchmarks with tag 'apps':
===========================

| Benchmark      | main-jit | jit279                 |
|----------------|:--------:|:----------------------:|
| 2to3           | 297 ms   | 279 ms: 1.07x faster   |
| chameleon      | 6.51 ms  | 6.78 ms: 1.04x slower  |
| docutils       | 2.74 sec | 2.52 sec: 1.09x faster |
| html5lib       | 65.4 ms  | 63.1 ms: 1.04x faster  |
| tornado_http   | 131 ms   | 126 ms: 1.04x faster   |
| Geometric mean | (ref)    | 1.04x faster           |

Benchmarks with tag 'asyncio':
==============================

| Benchmark                        | main-jit | jit279                 |
|----------------------------------|:--------:|:----------------------:|
| async_tree_io                    | 1.12 sec | 1.04 sec: 1.07x faster |
| async_tree_io_tg                 | 1.11 sec | 1.05 sec: 1.06x faster |
| async_tree_memoization_tg        | 551 ms   | 523 ms: 1.05x faster   |
| async_tree_eager_tg              | 83.6 ms  | 80.1 ms: 1.04x faster  |
| async_tree_memoization           | 541 ms   | 519 ms: 1.04x faster   |
| async_tree_eager_memoization     | 275 ms   | 265 ms: 1.04x faster   |
| async_tree_none_tg               | 423 ms   | 409 ms: 1.03x faster   |
| async_tree_eager                 | 116 ms   | 117 ms: 1.01x slower   |
| async_tree_eager_cpu_io_mixed    | 473 ms   | 477 ms: 1.01x slower   |
| async_tree_eager_cpu_io_mixed_tg | 409 ms   | 417 ms: 1.02x slower   |
| Geometric mean                   | (ref)    | 1.02x faster           |

Benchmark hidden because not significant (6): async_tree_eager_io_tg, async_tree_eager_memoization_tg, async_tree_cpu_io_mixed, async_tree_cpu_io_mixed_tg, async_tree_none, async_tree_eager_io

Benchmarks with tag 'math':
===========================

| Benchmark      | main-jit | jit279                |
|----------------|:--------:|:---------------------:|
| nbody          | 85.3 ms  | 83.8 ms: 1.02x faster |
| pidigits       | 191 ms   | 191 ms: 1.00x slower  |
| float          | 78.1 ms  | 78.5 ms: 1.01x slower |
| Geometric mean | (ref)    | 1.00x faster          |

Benchmarks with tag 'regex':
============================

| Benchmark      | main-jit | jit279                |
|----------------|:--------:|:---------------------:|
| regex_compile  | 172 ms   | 140 ms: 1.23x faster  |
| regex_dna      | 160 ms   | 155 ms: 1.03x faster  |
| regex_v8       | 21.4 ms  | 21.6 ms: 1.01x slower |
| regex_effbot   | 2.74 ms  | 2.85 ms: 1.04x slower |
| Geometric mean | (ref)    | 1.05x faster          |

Benchmarks with tag 'serialize':
================================

| Benchmark            | main-jit | jit279                 |
|----------------------|:--------:|:----------------------:|
| unpickle_pure_python | 244 us   | 225 us: 1.09x faster   |
| pickle_dict          | 32.3 us  | 30.8 us: 1.05x faster  |
| tomli_loads          | 2.24 sec | 2.16 sec: 1.04x faster |
| unpickle             | 15.6 us  | 15.1 us: 1.04x faster  |
| xml_etree_parse      | 142 ms   | 137 ms: 1.03x faster   |
| pickle_pure_python   | 291 us   | 281 us: 1.03x faster   |
| pickle_list          | 4.96 us  | 4.80 us: 1.03x faster  |
| xml_etree_process    | 63.4 ms  | 61.4 ms: 1.03x faster  |
| pickle               | 11.7 us  | 11.3 us: 1.03x faster  |
| xml_etree_iterparse  | 103 ms   | 100 ms: 1.03x faster   |
| xml_etree_generate   | 94.0 ms  | 91.8 ms: 1.02x faster  |
| json_loads           | 27.0 us  | 26.5 us: 1.02x faster  |
| json_dumps           | 10.6 ms  | 10.4 ms: 1.02x faster  |
| unpickle_list        | 4.85 us  | 4.77 us: 1.02x faster  |
| Geometric mean       | (ref)    | 1.03x faster           |

Benchmarks with tag 'startup':
==============================

| Benchmark              | main-jit | jit279                |
|------------------------|:--------:|:---------------------:|
| python_startup_no_site | 12.4 ms  | 9.89 ms: 1.26x faster |
| python_startup         | 13.4 ms  | 11.2 ms: 1.20x faster |
| Geometric mean         | (ref)    | 1.23x faster          |

Benchmarks with tag 'template':
===============================

| Benchmark      | main-jit | jit279                |
|----------------|:--------:|:---------------------:|
| genshi_xml     | 62.6 ms  | 52.6 ms: 1.19x faster |
| genshi_text    | 24.9 ms  | 21.8 ms: 1.15x faster |
| mako           | 11.4 ms  | 11.6 ms: 1.02x slower |
| Geometric mean | (ref)    | 1.10x faster          |

All benchmarks:
===============

| Benchmark                        | main-jit | jit279                 |
|----------------------------------|:--------:|:----------------------:|
| unpack_sequence                  | 136 ns   | 35.9 ns: 3.79x faster  |
| scimark_lu                       | 145 ms   | 108 ms: 1.34x faster   |
| python_startup_no_site           | 12.4 ms  | 9.89 ms: 1.26x faster  |
| regex_compile                    | 172 ms   | 140 ms: 1.23x faster   |
| python_startup                   | 13.4 ms  | 11.2 ms: 1.20x faster  |
| genshi_xml                       | 62.6 ms  | 52.6 ms: 1.19x faster  |
| raytrace                         | 307 ms   | 262 ms: 1.17x faster   |
| pprint_safe_repr                 | 946 ms   | 811 ms: 1.17x faster   |
| pprint_pformat                   | 1.99 sec | 1.71 sec: 1.16x faster |
| genshi_text                      | 24.9 ms  | 21.8 ms: 1.15x faster  |
| hexiom                           | 8.28 ms  | 7.30 ms: 1.13x faster  |
| pyflate                          | 507 ms   | 451 ms: 1.12x faster   |
| scimark_sor                      | 140 ms   | 124 ms: 1.12x faster   |
| richards_super                   | 56.0 ms  | 50.1 ms: 1.12x faster  |
| richards                         | 49.3 ms  | 44.2 ms: 1.11x faster  |
| go                               | 151 ms   | 136 ms: 1.11x faster   |
| deepcopy                         | 378 us   | 341 us: 1.11x faster   |
| scimark_monte_carlo              | 73.2 ms  | 66.8 ms: 1.10x faster  |
| docutils                         | 2.74 sec | 2.52 sec: 1.09x faster |
| unpickle_pure_python             | 244 us   | 225 us: 1.09x faster   |
| mdp                              | 3.10 sec | 2.86 sec: 1.08x faster |
| dask                             | 687 ms   | 638 ms: 1.08x faster   |
| async_tree_io                    | 1.12 sec | 1.04 sec: 1.07x faster |
| sqlglot_parse                    | 1.31 ms  | 1.22 ms: 1.07x faster  |
| deepcopy_memo                    | 37.0 us  | 34.5 us: 1.07x faster  |
| dulwich_log                      | 83.9 ms  | 78.5 ms: 1.07x faster  |
| sqlglot_transpile                | 1.63 ms  | 1.52 ms: 1.07x faster  |
| coverage                         | 370 ms   | 347 ms: 1.07x faster   |
| 2to3                             | 297 ms   | 279 ms: 1.07x faster   |
| nqueens                          | 97.4 ms  | 91.6 ms: 1.06x faster  |
| async_tree_io_tg                 | 1.11 sec | 1.05 sec: 1.06x faster |
| async_tree_memoization_tg        | 551 ms   | 523 ms: 1.05x faster   |
| deepcopy_reduce                  | 3.31 us  | 3.15 us: 1.05x faster  |
| sqlglot_optimize                 | 60.2 ms  | 57.3 ms: 1.05x faster  |
| pickle_dict                      | 32.3 us  | 30.8 us: 1.05x faster  |
| async_tree_eager_tg              | 83.6 ms  | 80.1 ms: 1.04x faster  |
| tornado_http                     | 131 ms   | 126 ms: 1.04x faster   |
| async_tree_memoization           | 541 ms   | 519 ms: 1.04x faster   |
| tomli_loads                      | 2.24 sec | 2.16 sec: 1.04x faster |
| unpickle                         | 15.6 us  | 15.1 us: 1.04x faster  |
| create_gc_cycles                 | 1.06 ms  | 1.02 ms: 1.04x faster  |
| async_tree_eager_memoization     | 275 ms   | 265 ms: 1.04x faster   |
| html5lib                         | 65.4 ms  | 63.1 ms: 1.04x faster  |
| async_tree_none_tg               | 423 ms   | 409 ms: 1.03x faster   |
| xml_etree_parse                  | 142 ms   | 137 ms: 1.03x faster   |
| pickle_pure_python               | 291 us   | 281 us: 1.03x faster   |
| logging_format                   | 8.01 us  | 7.75 us: 1.03x faster  |
| pickle_list                      | 4.96 us  | 4.80 us: 1.03x faster  |
| xml_etree_process                | 63.4 ms  | 61.4 ms: 1.03x faster  |
| pickle                           | 11.7 us  | 11.3 us: 1.03x faster  |
| regex_dna                        | 160 ms   | 155 ms: 1.03x faster   |
| logging_simple                   | 6.95 us  | 6.75 us: 1.03x faster  |
| meteor_contest                   | 101 ms   | 98.2 ms: 1.03x faster  |
| xml_etree_iterparse              | 103 ms   | 100 ms: 1.03x faster   |
| deltablue                        | 3.77 ms  | 3.66 ms: 1.03x faster  |
| telco                            | 8.19 ms  | 7.99 ms: 1.02x faster  |
| xml_etree_generate               | 94.0 ms  | 91.8 ms: 1.02x faster  |
| json_loads                       | 27.0 us  | 26.5 us: 1.02x faster  |
| pathlib                          | 21.8 ms  | 21.4 ms: 1.02x faster  |
| nbody                            | 85.3 ms  | 83.8 ms: 1.02x faster  |
| json_dumps                       | 10.6 ms  | 10.4 ms: 1.02x faster  |
| fannkuch                         | 423 ms   | 417 ms: 1.02x faster   |
| crypto_pyaes                     | 76.2 ms  | 74.9 ms: 1.02x faster  |
| unpickle_list                    | 4.85 us  | 4.77 us: 1.02x faster  |
| logging_silent                   | 103 ns   | 101 ns: 1.01x faster   |
| asyncio_tcp                      | 394 ms   | 389 ms: 1.01x faster   |
| asyncio_tcp_ssl                  | 1.33 sec | 1.31 sec: 1.01x faster |
| asyncio_websockets               | 442 ms   | 440 ms: 1.01x faster   |
| pidigits                         | 191 ms   | 191 ms: 1.00x slower   |
| float                            | 78.1 ms  | 78.5 ms: 1.01x slower  |
| gc_traversal                     | 3.31 ms  | 3.34 ms: 1.01x slower  |
| regex_v8                         | 21.4 ms  | 21.6 ms: 1.01x slower  |
| async_tree_eager                 | 116 ms   | 117 ms: 1.01x slower   |
| async_tree_eager_cpu_io_mixed    | 473 ms   | 477 ms: 1.01x slower   |
| coroutines                       | 22.2 ms  | 22.4 ms: 1.01x slower  |
| scimark_sparse_mat_mult          | 4.82 ms  | 4.87 ms: 1.01x slower  |
| scimark_fft                      | 331 ms   | 336 ms: 1.01x slower   |
| comprehensions                   | 18.2 us  | 18.4 us: 1.01x slower  |
| mako                             | 11.4 ms  | 11.6 ms: 1.02x slower  |
| async_tree_eager_cpu_io_mixed_tg | 409 ms   | 417 ms: 1.02x slower   |
| chameleon                        | 6.51 ms  | 6.78 ms: 1.04x slower  |
| regex_effbot                     | 2.74 ms  | 2.85 ms: 1.04x slower  |
| spectral_norm                    | 115 ms   | 125 ms: 1.09x slower   |
| bench_mp_pool                    | 42.0 ms  | 53.5 ms: 1.27x slower  |
| Geometric mean                   | (ref)    | 1.06x faster           |

Benchmark hidden because not significant (13): bench_thread_pool, async_tree_eager_io_tg, async_tree_eager_memoization_tg, async_tree_cpu_io_mixed, async_tree_cpu_io_mixed_tg, sqlite_synth, typing_runtime_protocols, async_tree_none, async_generators, sqlglot_normalize, generators, async_tree_eager_io, chaos

</p>

<p> Main with JIT (31.8MB) vs JIT92 (31.5MB): 


</p>


----------------------------------

<p>Writing at PyCON:</p>
<pre>./configure --enable-experimental-jit=interpreter --with-pydebug --enable-pystats && make -j4</pre>
<pre>PYTHON_OPT_DEBUG=5 ./python -X pystats -c 'for _ in range(1000): pass'</pre>


<style>
    code:not(.nocode):not(.language-python):not(.language-python3):not(.language-html):not(.language-js){
        --tw-text-opacity: 1;
        color: rgba(5, 120, 85, var(--tw-text-opacity));
    }
</style>


